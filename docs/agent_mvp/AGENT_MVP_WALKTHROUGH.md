# Agent MVP - Code Walkthrough

## ðŸš€ How to Walk Through the Code

This guide shows you the exact flow of the agent MVP, step by step.

---

## Part 1: Request Arrives at Endpoint

### File: `backend/routers/agent_mvp.py`

```python
@router.post("/agent-mvp/next-do", response_model=AgentMVPResponse)
@track(name="agent_mvp_next_do_endpoint")
async def next_do(
    constraints: Optional[SelectionConstraints] = None,
    current_user: dict = Depends(get_current_user),  # JWT verified here
) -> AgentMVPResponse:
```

**What happens:**
1. Request arrives with optional constraints
2. FastAPI verifies JWT token via `Depends(get_current_user)`
3. User object injected (contains `user["id"]`)
4. @track decorator starts Opik span
5. Calls `run_agent_mvp()`

---

## Part 2: Orchestrator Initializes State

### File: `backend/agent_mvp/graph.py`

```python
@track(name="agent_mvp_orchestrator")
async def run_agent_mvp(
    user_id: str,
    constraints: Optional[SelectionConstraints] = None,
) -> dict:
    """Main orchestration function"""
    
    # Create initial state
    state = GraphState(
        user_id=user_id,
        constraints=constraints,
    )
    
    # Execute nodes sequentially
    state = load_candidates(state)
    state = derive_constraints(state)
    state = llm_select_do(state)
    state = llm_coach(state)
    result = return_result(state)
    
    return result
```

**State object contains:**
- `user_id`: "uuid-123" (from JWT)
- `candidates`: [] (will be filled by load_candidates)
- `constraints`: SelectionConstraints (or None, will be derived)
- `active_do`: None (will be set by llm_select_do)
- `coach_message`: None (will be set by llm_coach)
- `error`: None (or error message if something fails)

---

## Part 3: Load Candidates (Node 1)

### File: `backend/agent_mvp/graph.py`

```python
@track(name="graph_load_candidates")
def load_candidates(state: GraphState) -> GraphState:
    """Load candidate tasks from Supabase for the user."""
    
    supabase = get_supabase()  # Existing helper
    
    # Query: get all open tasks for user
    response = (
        supabase.table("tasks")
        .select("id, title, priority, status, estimated_duration, due_at, tags, created_at")
        .eq("user_id", state.user_id)  # Filter to this user
        .in_("status", ["todo", "in_progress", "paused", "blocked"])  # Open tasks only
        .order("priority", desc=True)
        .order("due_at", desc=False)  # Most urgent first
        .limit(50)
        .execute()
    )
    
    # Parse rows into TaskCandidate objects
    candidates = []
    for row in response.data:
        candidate = TaskCandidate(
            id=row["id"],
            title=row["title"],
            priority=row.get("priority", "medium"),
            status=row.get("status", "todo"),
            estimated_duration=row.get("estimated_duration"),
            due_at=row.get("due_at"),  # Will be converted to datetime
            tags=row.get("tags") or [],
            created_at=row.get("created_at"),
        )
        candidates.append(candidate)
    
    state.candidates = candidates  # Update state
    return state
```

**Result:**
```python
state.candidates = [
    TaskCandidate(
        id="task-001",
        title="Fix login page CSS",
        priority="high",
        estimated_duration=45,
        ...
    ),
    TaskCandidate(
        id="task-002",
        title="Review pull request",
        priority="medium",
        estimated_duration=30,
        ...
    ),
    # ... up to 50 tasks
]
```

---

## Part 4: Derive Constraints (Node 2)

### File: `backend/agent_mvp/graph.py`

```python
@track(name="graph_derive_constraints")
def derive_constraints(state: GraphState) -> GraphState:
    """Derive selection constraints from daily_check_in or use defaults."""
    
    if state.constraints is None:
        # Try to load today's check-in
        supabase = get_supabase()
        today = date.today().isoformat()
        
        response = (
            supabase.table("daily_check_ins")
            .select("energy_level, mood, stress_level")
            .eq("user_id", state.user_id)
            .eq("date", today)
            .execute()
        )
        
        # Get energy from check-in, or default to 5
        energy_level = 5
        if response.data:
            energy_level = response.data[0].get("energy_level", 5)
        
        # Derive mode from energy
        mode = "quick" if energy_level <= 3 else "balanced" if energy_level <= 7 else "focus"
        
        # Create constraints
        state.constraints = SelectionConstraints(
            max_minutes=90,
            mode=mode,
            current_energy=energy_level,
        )
    
    return state
```

**Result:**
```python
state.constraints = SelectionConstraints(
    max_minutes=90,
    mode="balanced",  # Derived from energy=6
    current_energy=6,
)
```

---

## Part 5: LLM Select Do (Node 3)

### File: `backend/agent_mvp/graph.py` â†’ calls `backend/agent_mvp/llm_do_selector.py`

```python
@track(name="graph_llm_select_do")
def llm_select_do(state: GraphState) -> GraphState:
    """Call DoSelector agent to pick best task."""
    
    # Call the agent
    selector_output, is_valid = select_task(
        candidates=state.candidates,
        constraints=state.constraints,
    )
    
    # Find the actual task object
    selected_task = next(
        (c for c in state.candidates if c.id == selector_output.task_id),
        None,
    )
    
    # Create ActiveDo
    state.active_do = ActiveDo(
        task=selected_task,
        reason_codes=selector_output.reason_codes,
        alt_task_ids=selector_output.alt_task_ids,
    )
    
    return state
```

**Inside select_task() (agent):**

### File: `backend/agent_mvp/llm_do_selector.py`

```python
@track(name="do_selector_agent")
def select_task(
    candidates: List[TaskCandidate],
    constraints: SelectionConstraints,
) -> tuple[DoSelectorOutput, bool]:
    """Select the best task using Gemini."""
    
    # 1. Build prompt
    prompt = build_do_selector_prompt(candidates, constraints)
    # Returns something like:
    # "You are a task selection agent. Select ONE task from:"
    # "1. Task ID: task-001, Title: Fix login page CSS, Priority: high..."
    # "RESPOND WITH ONLY VALID JSON: {task_id, reason_codes, alt_task_ids}"
    
    # 2. Call Gemini
    gemini = get_gemini_client()
    raw_response = gemini.generate_json_response(
        prompt=prompt,
        temperature=0.5,  # Deterministic
        max_tokens=300,
    )
    
    # 3. Parse response
    # raw_response should be:
    # {
    #   "task_id": "task-001",
    #   "reason_codes": ["priority_high", "deadline_soon"],
    #   "alt_task_ids": ["task-002"]
    # }
    
    # 4. Validate
    output, is_valid = validate_do_selector_output(raw_response, candidates)
    # If task_id not in candidates, uses fallback:
    #   - Picks highest priority + shortest duration
    #   - Sets reason_codes = ["fallback_deterministic"]
    #   - is_valid = False
    
    return output, is_valid
```

**Result in state:**
```python
state.active_do = ActiveDo(
    task=TaskCandidate(
        id="task-001",
        title="Fix login page CSS",
        priority="high",
        estimated_duration=45,
        ...
    ),
    reason_codes=["priority_high", "deadline_soon"],
    alt_task_ids=["task-002"],
    selected_at=datetime.utcnow(),
)
```

---

## Part 6: LLM Coach (Node 4)

### File: `backend/agent_mvp/graph.py` â†’ calls `backend/agent_mvp/llm_coach.py`

```python
@track(name="graph_llm_coach")
def llm_coach(state: GraphState) -> GraphState:
    """Call Coach agent to generate motivational message."""
    
    coach_output, is_valid = generate_coaching_message(
        task=state.active_do.task,
        reason_codes=state.active_do.reason_codes,
        mode=state.constraints.mode,
    )
    
    state.coach_message = coach_output
    return state
```

**Inside generate_coaching_message() (agent):**

### File: `backend/agent_mvp/llm_coach.py`

```python
@track(name="coach_agent")
def generate_coaching_message(
    task: TaskCandidate,
    reason_codes: List[str],
    mode: str = "balanced",
) -> tuple[CoachOutput, bool]:
    """Generate coaching message using Gemini."""
    
    # 1. Build prompt
    prompt = build_coach_prompt(task, reason_codes, mode)
    # Returns something like:
    # "You are a brief, motivational coach. Generate a message for:"
    # "Task: Fix login page CSS, Priority: high, Duration: 45min"
    # "Reason codes: priority_high, deadline_soon"
    # "Respond with ONLY JSON: {title, message, next_step}"
    
    # 2. Call Gemini
    gemini = get_gemini_client()
    raw_response = gemini.generate_json_response(
        prompt=prompt,
        temperature=0.8,  # Creative
        max_tokens=200,
    )
    
    # 3. Parse response
    # raw_response should be:
    # {
    #   "title": "CSS time!",
    #   "message": "Let's fix the login page. You've got this.",
    #   "next_step": "Open the CSS file."
    # }
    
    # 4. Validate
    output, is_valid = validate_coach_output(raw_response)
    # Checks:
    #   - title: 1-100 chars âœ…
    #   - message: 1-2 sentences, â‰¤300 chars âœ…
    #   - next_step: < 10 words âœ…
    # If invalid, fallback to:
    #   {
    #     "title": "Let's go",
    #     "message": "You've got this.",
    #     "next_step": "Begin."
    #   }
    
    return output, is_valid
```

**Result in state:**
```python
state.coach_message = CoachOutput(
    title="CSS time!",
    message="Let's fix the login page. You've got this.",
    next_step="Open the CSS file.",
)
```

---

## Part 7: Return Result (Node 5)

### File: `backend/agent_mvp/graph.py`

```python
@track(name="graph_return_result")
def return_result(state: GraphState) -> dict:
    """Prepare final response from state."""
    
    # Check for errors
    if state.error:
        return {
            "success": False,
            "error": state.error,
            "data": {},
        }
    
    # Format response
    return {
        "success": True,
        "error": None,
        "data": {
            "active_do": {
                "task_id": state.active_do.task.id,
                "task_title": state.active_do.task.title,
                "reason_codes": state.active_do.reason_codes,
                "alt_task_ids": state.active_do.alt_task_ids,
                "selected_at": state.active_do.selected_at.isoformat(),
            },
            "coach_message": {
                "title": state.coach_message.title,
                "message": state.coach_message.message,
                "next_step": state.coach_message.next_step,
            },
        },
    }
```

**Result:**
```python
{
    "success": True,
    "data": {
        "active_do": {
            "task_id": "task-001",
            "task_title": "Fix login page CSS",
            "reason_codes": ["priority_high", "deadline_soon"],
            "alt_task_ids": ["task-002"],
            "selected_at": "2026-01-28T12:34:56.789012Z"
        },
        "coach_message": {
            "title": "CSS time!",
            "message": "Let's fix the login page. You've got this.",
            "next_step": "Open the CSS file."
        }
    }
}
```

---

## Part 8: Response Returns to Client

### File: `backend/routers/agent_mvp.py`

```python
@router.post("/agent-mvp/next-do", response_model=AgentMVPResponse)
@track(name="agent_mvp_next_do_endpoint")
async def next_do(...) -> AgentMVPResponse:
    ...
    result = await run_agent_mvp(user_id, constraints)
    
    if not result["success"]:
        raise HTTPException(status_code=500, detail=result["error"])
    
    return AgentMVPResponse(
        success=True,
        data=result["data"],
    )
    # Returns 200 OK with JSON body
```

**Client receives:**
```json
HTTP/1.1 200 OK
Content-Type: application/json

{
  "success": true,
  "data": {
    "active_do": {...},
    "coach_message": {...}
  },
  "error": null
}
```

---

## Complete Request/Response Flow Diagram

```
CLIENT REQUEST
    â†“
POST /agent-mvp/next-do + JWT
    â†“
FastAPI Middleware
  â”œâ”€ CORS check âœ“
  â”œâ”€ JWT verification âœ“
  â””â”€ Request size limit âœ“
    â†“
next_do() endpoint
    â”œâ”€ @track("agent_mvp_next_do_endpoint") â†’ Opik
    â””â”€ calls: run_agent_mvp(user_id)
        â†“
    run_agent_mvp() orchestrator
        â”œâ”€ @track("agent_mvp_orchestrator") â†’ Opik
        â”œâ”€ Node 1: load_candidates()
        â”‚   â”œâ”€ @track("graph_load_candidates") â†’ Opik
        â”‚   â””â”€ Supabase query â†’ TaskCandidate[]
        â”œâ”€ Node 2: derive_constraints()
        â”‚   â”œâ”€ @track("graph_derive_constraints") â†’ Opik
        â”‚   â””â”€ Supabase query â†’ SelectionConstraints
        â”œâ”€ Node 3: llm_select_do()
        â”‚   â”œâ”€ @track("graph_llm_select_do") â†’ Opik
        â”‚   â””â”€ select_task() agent
        â”‚       â”œâ”€ @track("do_selector_agent") â†’ Opik
        â”‚       â”œâ”€ build_do_selector_prompt()
        â”‚       â”œâ”€ Gemini API call
        â”‚       â”‚   â””â”€ @track("gemini_call") â†’ Opik (token usage logged)
        â”‚       â””â”€ validate_do_selector_output()
        â”‚           â””â”€ fallback if invalid
        â”œâ”€ Node 4: llm_coach()
        â”‚   â”œâ”€ @track("graph_llm_coach") â†’ Opik
        â”‚   â””â”€ generate_coaching_message() agent
        â”‚       â”œâ”€ @track("coach_agent") â†’ Opik
        â”‚       â”œâ”€ build_coach_prompt()
        â”‚       â”œâ”€ Gemini API call
        â”‚       â”‚   â””â”€ @track("gemini_call") â†’ Opik
        â”‚       â””â”€ validate_coach_output()
        â”‚           â””â”€ fallback if invalid
        â””â”€ return_result()
            â”œâ”€ @track("graph_return_result") â†’ Opik
            â””â”€ Format JSON response
        â†“
    return result dict
        â†“
next_do() endpoint
    â””â”€ return AgentMVPResponse(success=True, data=...)
        â†“
FastAPI Response
    â”œâ”€ Status: 200 OK
    â”œâ”€ Headers: Content-Type: application/json
    â”œâ”€ Security headers (X-Content-Type-Options, etc.)
    â””â”€ Body: JSON response
        â†“
CLIENT RESPONSE
    â†“
Client displays:
  - Task title: "Fix login page CSS"
  - Coach message: "Let's fix the login page. You've got this."
  - Next step: "Open the CSS file."
    â†“
ALL TRACES VISIBLE IN OPIK DASHBOARD
```

---

## Key Data Structures

### TaskCandidate (From Supabase)
```python
TaskCandidate(
    id="uuid",
    title="Fix login page CSS",
    priority="high",  # low/medium/high/urgent
    status="in_progress",  # todo/in_progress/paused/blocked/completed
    estimated_duration=45,  # minutes
    due_at=datetime(...),  # when due
    tags=["frontend", "bug"],
    created_at=datetime(...),
)
```

### SelectionConstraints (From check-in or request)
```python
SelectionConstraints(
    max_minutes=90,
    mode="balanced",  # focus/quick/learning/balanced
    current_energy=6,  # 1-10
    avoid_tags=[],
    prefer_priority=None,
)
```

### DoSelectorOutput (From Gemini)
```python
DoSelectorOutput(
    task_id="uuid",  # MUST be in candidates
    reason_codes=["priority_high", "deadline_soon"],
    alt_task_ids=["uuid2"],
)
```

### CoachOutput (From Gemini)
```python
CoachOutput(
    title="CSS time!",  # 1-100 chars
    message="Let's fix the login page. You've got this.",  # 1-2 sentences
    next_step="Open the CSS file.",  # <10 words
)
```

---

## Error Handling

### If load_candidates fails
```python
state.error = "Failed to load tasks"
â†’ skip to return_result()
â†’ return { "success": False, "error": "..." }
```

### If Gemini returns invalid JSON
```python
try:
    raw_response = gemini.generate_json_response(...)
except ValueError:
    # Fallback: validate_do_selector_output({}, candidates)
    # Picks deterministic task
    is_valid = False
```

### If task_id not in candidates
```python
if output.task_id not in candidate_ids:
    # Use fallback
    output = fallback_do_selector(candidates)
    is_valid = False
```

### If coach message > 300 chars
```python
try:
    output = CoachOutput(**raw_response)  # Pydantic validation
except ValueError:
    # Fallback
    output = CoachOutput(
        title="Let's go",
        message="You've got this.",
        next_step="Begin.",
    )
    is_valid = False
```

---

## Testing This Flow

### Mock Test Example

```python
def test_complete_flow():
    # 1. Setup mock tasks
    candidates = [
        TaskCandidate(id="task-001", title="Fix CSS", priority="high"),
        TaskCandidate(id="task-002", title="Review PR", priority="medium"),
    ]
    
    # 2. Mock Gemini
    with patch("agent_mvp.gemini_client.get_gemini_client") as mock_gemini:
        mock_client = Mock()
        mock_client.generate_json_response.return_value = {
            "task_id": "task-001",
            "reason_codes": ["priority_high"],
            "alt_task_ids": [],
        }
        mock_gemini.return_value = mock_client
        
        # 3. Call agent
        output, is_valid = select_task(candidates, SelectionConstraints())
        
        # 4. Assert
        assert output.task_id == "task-001"
        assert is_valid == True
```

---

## Performance Notes

**Typical latencies:**
- load_candidates: 100-200ms (Supabase)
- derive_constraints: 50-150ms (Supabase)
- llm_select_do: 1-3 seconds (Gemini)
- llm_coach: 0.5-1.5 seconds (Gemini)
- **Total: 2-5 seconds per request**

**Token usage:**
- DoSelector: ~500 input + 50 output tokens
- Coach: ~400 input + 20 output tokens
- **Total: ~970 tokens â‰ˆ $0.0002 per request**

---

## Summary

The agent MVP is a well-orchestrated system:

1. **Endpoint** receives request with JWT
2. **Orchestrator** initializes GraphState
3. **load_candidates** fetches tasks from Supabase
4. **derive_constraints** gets user's energy level
5. **DoSelector agent** picks best task (with fallback)
6. **Coach agent** generates motivational message (with fallback)
7. **return_result** formats response
8. **Client** receives task recommendation with coaching

All steps are traced in Opik, validated strictly, and fall back gracefully if anything goes wrong.

---

Created: January 28, 2026
Status: âœ… COMPLETE
